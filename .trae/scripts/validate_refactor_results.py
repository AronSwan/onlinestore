#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Refactor Results Validator
Validates the results of code refactoring operations

Generated by AI assistant on 2025-01-26
Source: Refactor validation requirements
"""

import json
import sys
import os
import subprocess
from pathlib import Path
from typing import Dict, Any, List, Tuple

def validate_code_quality_metrics(results_file: str) -> List[str]:
    """
    Validate code quality metrics from refactor results
    """
    issues = []
    
    try:
        with open(results_file, 'r', encoding='utf-8') as f:
            results = json.load(f)
    except Exception as e:
        return [f"Failed to read results file: {e}"]
    
    # Check for required metrics
    required_metrics = ['complexity', 'maintainability', 'test_coverage']
    for metric in required_metrics:
        if metric not in results:
            issues.append(f"Missing required metric: {metric}")
    
    # Validate complexity thresholds
    if 'complexity' in results:
        complexity = results['complexity']
        if isinstance(complexity, dict):
            avg_complexity = complexity.get('average', 0)
            if avg_complexity > 10:
                issues.append(f"Average complexity too high: {avg_complexity} (threshold: 10)")
    
    # Validate test coverage
    if 'test_coverage' in results:
        coverage = results['test_coverage']
        if isinstance(coverage, dict):
            line_coverage = coverage.get('line_coverage', 0)
            if line_coverage < 80:
                issues.append(f"Line coverage too low: {line_coverage}% (minimum: 80%)")
    
    return issues

def validate_security_improvements(results_file: str) -> List[str]:
    """
    Validate security improvements from refactoring
    """
    issues = []
    
    try:
        with open(results_file, 'r', encoding='utf-8') as f:
            results = json.load(f)
    except Exception as e:
        return [f"Failed to read results file: {e}"]
    
    # Check security metrics
    if 'security' in results:
        security = results['security']
        
        # Check for vulnerability reduction
        if 'vulnerabilities' in security:
            vuln_count = security['vulnerabilities'].get('total', 0)
            if vuln_count > 5:
                issues.append(f"Too many vulnerabilities remaining: {vuln_count} (threshold: 5)")
        
        # Check for security best practices
        if 'best_practices' in security:
            practices = security['best_practices']
            compliance_rate = practices.get('compliance_rate', 0)
            if compliance_rate < 90:
                issues.append(f"Security best practices compliance too low: {compliance_rate}% (minimum: 90%)")
    
    return issues

def validate_performance_metrics(results_file: str) -> List[str]:
    """
    Validate performance improvements from refactoring
    """
    issues = []
    
    try:
        with open(results_file, 'r', encoding='utf-8') as f:
            results = json.load(f)
    except Exception as e:
        return [f"Failed to read results file: {e}"]
    
    # Check performance metrics
    if 'performance' in results:
        performance = results['performance']
        
        # Check response time improvements
        if 'response_time' in performance:
            response_time = performance['response_time']
            avg_response = response_time.get('average_ms', 0)
            if avg_response > 250:
                issues.append(f"Average response time too high: {avg_response}ms (threshold: 250ms)")
        
        # Check memory usage
        if 'memory_usage' in performance:
            memory = performance['memory_usage']
            peak_memory = memory.get('peak_mb', 0)
            if peak_memory > 512:
                issues.append(f"Peak memory usage too high: {peak_memory}MB (threshold: 512MB)")
    
    return issues

def validate_code_structure(project_path: str) -> List[str]:
    """
    Validate code structure after refactoring
    """
    issues = []
    
    # Check for common anti-patterns
    try:
        # Look for large files (potential code smell)
        for root, dirs, files in os.walk(project_path):
            # Skip node_modules and other build directories
            dirs[:] = [d for d in dirs if d not in ['node_modules', 'dist', 'build', '.git']]
            
            for file in files:
                if file.endswith(('.js', '.ts', '.py')):
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            line_count = sum(1 for _ in f)
                        
                        if line_count > 500:
                            rel_path = os.path.relpath(file_path, project_path)
                            issues.append(f"Large file detected: {rel_path} ({line_count} lines)")
                    except Exception:
                        continue
    except Exception as e:
        issues.append(f"Failed to analyze code structure: {e}")
    
    return issues

def run_linting_checks(project_path: str) -> List[str]:
    """
    Run linting checks to validate code quality
    """
    issues = []
    
    # Check if ESLint is available and run it
    try:
        result = subprocess.run(
            ['npx', 'eslint', '--format', 'json', '.'],
            cwd=project_path,
            capture_output=True,
            text=True,
            timeout=60
        )
        
        if result.returncode == 0:
            # Parse ESLint output
            try:
                eslint_results = json.loads(result.stdout)
                error_count = sum(len(file_result.get('messages', [])) for file_result in eslint_results)
                if error_count > 10:
                    issues.append(f"Too many ESLint issues: {error_count} (threshold: 10)")
            except json.JSONDecodeError:
                pass
    except (subprocess.TimeoutExpired, FileNotFoundError):
        # ESLint not available or timed out
        pass
    
    return issues

def main():
    if len(sys.argv) < 2:
        print("Usage: python validate_refactor_results.py <results_file> [project_path]")
        sys.exit(1)
    
    results_file = sys.argv[1]
    project_path = sys.argv[2] if len(sys.argv) > 2 else os.getcwd()
    
    if not os.path.exists(results_file):
        print(f"Error: Results file '{results_file}' does not exist")
        sys.exit(1)
    
    # Run all validation checks
    all_issues = []
    all_issues.extend(validate_code_quality_metrics(results_file))
    all_issues.extend(validate_security_improvements(results_file))
    all_issues.extend(validate_performance_metrics(results_file))
    all_issues.extend(validate_code_structure(project_path))
    all_issues.extend(run_linting_checks(project_path))
    
    if all_issues:
        print("Refactor Validation Issues Found:")
        for i, issue in enumerate(all_issues, 1):
            print(f"  {i}. {issue}")
        
        # Create validation report
        report = {
            'validation_status': 'FAILED',
            'issues_count': len(all_issues),
            'issues': all_issues,
            'timestamp': subprocess.check_output(['date'], text=True).strip()
        }
        
        report_file = os.path.join(os.path.dirname(results_file), 'validation_report.json')
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nValidation report saved to: {report_file}")
        sys.exit(1)
    else:
        print("All refactor validation checks passed.")
        
        # Create success report
        report = {
            'validation_status': 'PASSED',
            'issues_count': 0,
            'timestamp': subprocess.check_output(['date'], text=True).strip()
        }
        
        report_file = os.path.join(os.path.dirname(results_file), 'validation_report.json')
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        sys.exit(0)

if __name__ == '__main__':
    main()