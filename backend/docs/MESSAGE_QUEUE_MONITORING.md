# ğŸ“Š æ¶ˆæ¯é˜Ÿåˆ—ç›‘æ§æŒ‡å—

æœ¬æ–‡æ¡£æä¾›äº†å®Œæ•´çš„æ¶ˆæ¯é˜Ÿåˆ—ç›‘æ§æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ Redpanda/Kafka é›†ç¾¤ç›‘æ§ã€æ€§èƒ½æŒ‡æ ‡ã€å‘Šè­¦é…ç½®å’Œæ•…éšœæ’é™¤ã€‚

## ğŸ“‹ ç›®å½•

- [ç›‘æ§æ¶æ„æ¦‚è§ˆ](#ç›‘æ§æ¶æ„æ¦‚è§ˆ)
- [æ ¸å¿ƒæŒ‡æ ‡](#æ ¸å¿ƒæŒ‡æ ‡)
- [Prometheus é…ç½®](#prometheus-é…ç½®)
- [Grafana ä»ªè¡¨æ¿](#grafana-ä»ªè¡¨æ¿)
- [å‘Šè­¦è§„åˆ™](#å‘Šè­¦è§„åˆ™)
- [æ—¥å¿—ç›‘æ§](#æ—¥å¿—ç›‘æ§)
- [æ€§èƒ½è°ƒä¼˜](#æ€§èƒ½è°ƒä¼˜)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

---

## ğŸ—ï¸ ç›‘æ§æ¶æ„æ¦‚è§ˆ

### ç›‘æ§ç»„ä»¶æ¶æ„

```mermaid
graph TB
    A[Redpanda é›†ç¾¤] --> B[JMX Exporter]
    A --> C[Node Exporter]
    A --> D[Log Aggregation]
    
    B --> E[Prometheus]
    C --> E
    D --> F[Elasticsearch]
    
    E --> G[Grafana]
    E --> H[AlertManager]
    F --> I[Kibana]
    
    H --> J[Slack/Email]
    H --> K[PagerDuty]
    
    G --> L[Dashboard]
    I --> M[Log Analysis]
```

### ç›‘æ§å±‚çº§

| å±‚çº§ | ç»„ä»¶ | ç›‘æ§å†…å®¹ | å·¥å…· |
|------|------|----------|------|
| **åŸºç¡€è®¾æ–½** | æœåŠ¡å™¨/å®¹å™¨ | CPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œ | Node Exporter |
| **åº”ç”¨å±‚** | Redpanda/Kafka | ååé‡ã€å»¶è¿Ÿã€åˆ†åŒºçŠ¶æ€ | JMX Exporter |
| **ä¸šåŠ¡å±‚** | æ¶ˆæ¯å¤„ç† | æ¶ˆæ¯ç§¯å‹ã€å¤„ç†é€Ÿåº¦ã€é”™è¯¯ç‡ | è‡ªå®šä¹‰æŒ‡æ ‡ |
| **ç”¨æˆ·ä½“éªŒ** | ç«¯åˆ°ç«¯ | æ¶ˆæ¯ä¼ é€’å»¶è¿Ÿã€å¯ç”¨æ€§ | åˆæˆç›‘æ§ |

---

## ğŸ“ˆ æ ¸å¿ƒæŒ‡æ ‡

### 1. é›†ç¾¤å¥åº·æŒ‡æ ‡

#### Broker çŠ¶æ€æŒ‡æ ‡

```yaml
# Broker åœ¨çº¿çŠ¶æ€
kafka_server_broker_state:
  description: "Broker çŠ¶æ€ (0=ç¦»çº¿, 1=åœ¨çº¿)"
  type: gauge
  labels: [broker_id, cluster]

# æ§åˆ¶å™¨çŠ¶æ€
kafka_controller_active_controller_count:
  description: "æ´»è·ƒæ§åˆ¶å™¨æ•°é‡"
  type: gauge
  expected_value: 1

# åˆ†åŒºé¢†å¯¼è€…æ•°é‡
kafka_server_replica_manager_leader_count:
  description: "å½“å‰ Broker ä½œä¸ºé¢†å¯¼è€…çš„åˆ†åŒºæ•°"
  type: gauge
  labels: [broker_id]

# æœªåŒæ­¥å‰¯æœ¬æ•°é‡
kafka_server_replica_manager_under_replicated_partitions:
  description: "æœªå®Œå…¨åŒæ­¥çš„åˆ†åŒºæ•°é‡"
  type: gauge
  labels: [broker_id]
  alert_threshold: "> 0"
```

#### é›†ç¾¤çº§åˆ«æŒ‡æ ‡

```yaml
# æ€»åˆ†åŒºæ•°
kafka_server_broker_topic_metrics_partition_count:
  description: "é›†ç¾¤æ€»åˆ†åŒºæ•°"
  type: gauge

# ç¦»çº¿åˆ†åŒºæ•°
kafka_controller_offline_partitions_count:
  description: "ç¦»çº¿åˆ†åŒºæ•°é‡"
  type: gauge
  alert_threshold: "> 0"

# é¦–é€‰å‰¯æœ¬ä¸å¹³è¡¡ç‡
kafka_controller_preferred_replica_imbalance_count:
  description: "é¦–é€‰å‰¯æœ¬ä¸å¹³è¡¡çš„åˆ†åŒºæ•°"
  type: gauge
```

### 2. æ€§èƒ½æŒ‡æ ‡

#### ååé‡æŒ‡æ ‡

```yaml
# æ¶ˆæ¯ç”Ÿäº§é€Ÿç‡
kafka_server_broker_topic_metrics_messages_in_per_sec:
  description: "æ¯ç§’æ¥æ”¶æ¶ˆæ¯æ•°"
  type: rate
  labels: [topic, broker_id]

# å­—èŠ‚ç”Ÿäº§é€Ÿç‡
kafka_server_broker_topic_metrics_bytes_in_per_sec:
  description: "æ¯ç§’æ¥æ”¶å­—èŠ‚æ•°"
  type: rate
  labels: [topic, broker_id]

# æ¶ˆæ¯æ¶ˆè´¹é€Ÿç‡
kafka_server_broker_topic_metrics_bytes_out_per_sec:
  description: "æ¯ç§’å‘é€å­—èŠ‚æ•°"
  type: rate
  labels: [topic, broker_id]

# è¯·æ±‚å¤„ç†é€Ÿç‡
kafka_network_request_metrics_request_rate:
  description: "æ¯ç§’è¯·æ±‚æ•°"
  type: rate
  labels: [request_type, broker_id]
```

#### å»¶è¿ŸæŒ‡æ ‡

```yaml
# ç”Ÿäº§è€…è¯·æ±‚å»¶è¿Ÿ
kafka_network_request_metrics_total_time_ms:
  description: "è¯·æ±‚æ€»å¤„ç†æ—¶é—´"
  type: histogram
  labels: [request_type, broker_id]
  percentiles: [50, 95, 99]

# æ¶ˆè´¹è€…æ‹‰å–å»¶è¿Ÿ
kafka_server_fetch_session_cache_eviction_rate:
  description: "æ‹‰å–ä¼šè¯ç¼“å­˜é€å‡ºç‡"
  type: rate

# ç«¯åˆ°ç«¯å»¶è¿Ÿ
kafka_producer_record_queue_time_avg:
  description: "æ¶ˆæ¯åœ¨ç”Ÿäº§è€…é˜Ÿåˆ—ä¸­çš„å¹³å‡ç­‰å¾…æ—¶é—´"
  type: gauge
```

### 3. èµ„æºä½¿ç”¨æŒ‡æ ‡

#### å†…å­˜ä½¿ç”¨

```yaml
# JVM å †å†…å­˜ä½¿ç”¨
jvm_memory_bytes_used:
  description: "JVM å†…å­˜ä½¿ç”¨é‡"
  type: gauge
  labels: [area, broker_id]

# é¡µç¼“å­˜å‘½ä¸­ç‡
kafka_log_log_size:
  description: "æ—¥å¿—æ–‡ä»¶å¤§å°"
  type: gauge
  labels: [topic, partition, broker_id]

# ç½‘ç»œç¼“å†²åŒºä½¿ç”¨
kafka_server_socket_server_metrics_network_processor_avg_idle_percent:
  description: "ç½‘ç»œå¤„ç†å™¨å¹³å‡ç©ºé—²ç™¾åˆ†æ¯”"
  type: gauge
```

#### ç£ç›˜ä½¿ç”¨

```yaml
# ç£ç›˜ä½¿ç”¨ç‡
node_filesystem_avail_bytes:
  description: "å¯ç”¨ç£ç›˜ç©ºé—´"
  type: gauge
  labels: [device, mountpoint]

# ç£ç›˜ I/O
node_disk_io_time_seconds_total:
  description: "ç£ç›˜ I/O æ—¶é—´"
  type: counter
  labels: [device]

# æ—¥å¿—æ®µæ•°é‡
kafka_log_num_log_segments:
  description: "æ—¥å¿—æ®µæ•°é‡"
  type: gauge
  labels: [topic, partition]
```

---

## âš™ï¸ Prometheus é…ç½®

### 1. JMX Exporter é…ç½®

åˆ›å»º `jmx_exporter_config.yml`ï¼š

```yaml
# JMX Exporter é…ç½®æ–‡ä»¶
startDelaySeconds: 0
ssl: false
lowercaseOutputName: false
lowercaseOutputLabelNames: false

# ç™½åå•è§„åˆ™
whitelistObjectNames:
  - "kafka.server:type=BrokerTopicMetrics,name=*"
  - "kafka.server:type=ReplicaManager,name=*"
  - "kafka.server:type=KafkaRequestHandlerPool,name=*"
  - "kafka.network:type=RequestMetrics,name=*"
  - "kafka.controller:type=KafkaController,name=*"
  - "kafka.server:type=SessionExpireListener,name=*"
  - "kafka.log:type=LogFlushStats,name=*"
  - "java.lang:type=Memory"
  - "java.lang:type=GarbageCollector,name=*"

# é»‘åå•è§„åˆ™
blacklistObjectNames:
  - "kafka.consumer:type=*,id=*"
  - "kafka.producer:type=*,id=*"

# æŒ‡æ ‡è½¬æ¢è§„åˆ™
rules:
  # Broker Topic Metrics
  - pattern: kafka.server<type=BrokerTopicMetrics, name=(.+), topic=(.+)><>Count
    name: kafka_server_broker_topic_metrics_$1_total
    labels:
      topic: "$2"
    type: COUNTER

  - pattern: kafka.server<type=BrokerTopicMetrics, name=(.+), topic=(.+)><>OneMinuteRate
    name: kafka_server_broker_topic_metrics_$1_per_sec
    labels:
      topic: "$2"
    type: GAUGE

  # Request Metrics
  - pattern: kafka.network<type=RequestMetrics, name=(.+), request=(.+)><>Count
    name: kafka_network_request_metrics_$1_total
    labels:
      request: "$2"
    type: COUNTER

  - pattern: kafka.network<type=RequestMetrics, name=(.+), request=(.+)><>OneMinuteRate
    name: kafka_network_request_metrics_$1_per_sec
    labels:
      request: "$2"
    type: GAUGE

  # Controller Metrics
  - pattern: kafka.controller<type=KafkaController, name=(.+)><>Value
    name: kafka_controller_$1
    type: GAUGE

  # Replica Manager
  - pattern: kafka.server<type=ReplicaManager, name=(.+)><>Value
    name: kafka_server_replica_manager_$1
    type: GAUGE

  # JVM Metrics
  - pattern: java.lang<type=Memory><HeapMemoryUsage>(.+)
    name: jvm_memory_heap_$1
    type: GAUGE

  - pattern: java.lang<type=Memory><NonHeapMemoryUsage>(.+)
    name: jvm_memory_nonheap_$1
    type: GAUGE

  - pattern: java.lang<type=GarbageCollector, name=(.+)><>CollectionCount
    name: jvm_gc_collection_count_total
    labels:
      gc: "$1"
    type: COUNTER
```

### 2. Prometheus æŠ“å–é…ç½®

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "kafka_alerts.yml"

scrape_configs:
  # Redpanda/Kafka JMX æŒ‡æ ‡
  - job_name: 'kafka-jmx'
    static_configs:
      - targets: 
          - 'kafka-1:9308'
          - 'kafka-2:9308'
          - 'kafka-3:9308'
    scrape_interval: 10s
    metrics_path: /metrics

  # Node Exporter æŒ‡æ ‡
  - job_name: 'kafka-nodes'
    static_configs:
      - targets:
          - 'kafka-1:9100'
          - 'kafka-2:9100'
          - 'kafka-3:9100'
    scrape_interval: 15s

  # è‡ªå®šä¹‰åº”ç”¨æŒ‡æ ‡
  - job_name: 'kafka-lag-exporter'
    static_configs:
      - targets: ['kafka-lag-exporter:9999']
    scrape_interval: 30s

  # Redpanda ç‰¹å®šæŒ‡æ ‡
  - job_name: 'redpanda-admin'
    static_configs:
      - targets: 
          - 'redpanda-1:9644'
          - 'redpanda-2:9644'
          - 'redpanda-3:9644'
    metrics_path: /metrics
    scrape_interval: 15s

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

### 3. Kafka Lag Exporter é…ç½®

```yaml
# kafka-lag-exporter.yml
clusters:
  - name: "production-cluster"
    bootstrap-brokers: "kafka-1:9092,kafka-2:9092,kafka-3:9092"
    group-whitelist:
      - "user-service-group"
      - "order-service-group"
      - "notification-service-group"
    topic-whitelist:
      - "user-events"
      - "order-events"
      - "notification-events"
    consumer-properties:
      security.protocol: "PLAINTEXT"
    admin-client-properties:
      security.protocol: "PLAINTEXT"

watchers:
  strimzi: false

metric-whitelist:
  - "kafka_consumer_lag_sum"
  - "kafka_consumer_lag_max"
  - "kafka_consumer_current_offset"
  - "kafka_consumer_log_end_offset"

poll-interval: 30
lookup-table-size: 120
```

---

## ğŸ“Š Grafana ä»ªè¡¨æ¿

### 1. é›†ç¾¤æ¦‚è§ˆä»ªè¡¨æ¿

```json
{
  "dashboard": {
    "title": "Kafka é›†ç¾¤æ¦‚è§ˆ",
    "panels": [
      {
        "title": "é›†ç¾¤å¥åº·çŠ¶æ€",
        "type": "stat",
        "targets": [
          {
            "expr": "kafka_server_broker_state",
            "legendFormat": "Broker {{broker_id}}"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "red", "value": 0},
                {"color": "green", "value": 1}
              ]
            }
          }
        }
      },
      {
        "title": "æ¶ˆæ¯ååé‡",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(kafka_server_broker_topic_metrics_messages_in_per_sec[5m]))",
            "legendFormat": "Messages In/sec"
          },
          {
            "expr": "sum(rate(kafka_server_broker_topic_metrics_bytes_in_per_sec[5m]))",
            "legendFormat": "Bytes In/sec"
          }
        ],
        "yAxes": [
          {
            "label": "Messages/sec",
            "min": 0
          },
          {
            "label": "Bytes/sec",
            "min": 0
          }
        ]
      },
      {
        "title": "åˆ†åŒºçŠ¶æ€",
        "type": "stat",
        "targets": [
          {
            "expr": "kafka_controller_offline_partitions_count",
            "legendFormat": "ç¦»çº¿åˆ†åŒº"
          },
          {
            "expr": "sum(kafka_server_replica_manager_under_replicated_partitions)",
            "legendFormat": "æœªåŒæ­¥åˆ†åŒº"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "green", "value": 0},
                {"color": "red", "value": 1}
              ]
            }
          }
        }
      }
    ]
  }
}
```

### 2. æ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿

```json
{
  "dashboard": {
    "title": "Kafka æ€§èƒ½ç›‘æ§",
    "panels": [
      {
        "title": "è¯·æ±‚å»¶è¿Ÿåˆ†å¸ƒ",
        "type": "heatmap",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(kafka_network_request_metrics_total_time_ms_bucket[5m]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.99, rate(kafka_network_request_metrics_total_time_ms_bucket[5m]))",
            "legendFormat": "99th percentile"
          }
        ]
      },
      {
        "title": "æ¶ˆè´¹è€…å»¶è¿Ÿ",
        "type": "graph",
        "targets": [
          {
            "expr": "kafka_consumer_lag_sum by (group, topic)",
            "legendFormat": "{{group}} - {{topic}}"
          }
        ],
        "alert": {
          "conditions": [
            {
              "query": {"queryType": "", "refId": "A"},
              "reducer": {"type": "last", "params": []},
              "evaluator": {"params": [1000], "type": "gt"}
            }
          ],
          "executionErrorState": "alerting",
          "noDataState": "no_data",
          "frequency": "10s",
          "handler": 1,
          "name": "æ¶ˆè´¹è€…å»¶è¿Ÿè¿‡é«˜",
          "message": "æ¶ˆè´¹è€…ç»„ {{group}} åœ¨ä¸»é¢˜ {{topic}} ä¸Šçš„å»¶è¿Ÿè¶…è¿‡ 1000 æ¡æ¶ˆæ¯"
        }
      },
      {
        "title": "ç£ç›˜ä½¿ç”¨ç‡",
        "type": "graph",
        "targets": [
          {
            "expr": "(1 - node_filesystem_avail_bytes{mountpoint=\"/kafka-logs\"} / node_filesystem_size_bytes{mountpoint=\"/kafka-logs\"}) * 100",
            "legendFormat": "{{instance}}"
          }
        ],
        "yAxes": [
          {
            "label": "ä½¿ç”¨ç‡ (%)",
            "min": 0,
            "max": 100
          }
        ]
      }
    ]
  }
}
```

### 3. ä¸šåŠ¡ç›‘æ§ä»ªè¡¨æ¿

```json
{
  "dashboard": {
    "title": "ä¸šåŠ¡æ¶ˆæ¯ç›‘æ§",
    "panels": [
      {
        "title": "å„ä¸»é¢˜æ¶ˆæ¯é‡",
        "type": "graph",
        "targets": [
          {
            "expr": "sum(rate(kafka_server_broker_topic_metrics_messages_in_per_sec[5m])) by (topic)",
            "legendFormat": "{{topic}}"
          }
        ]
      },
      {
        "title": "é”™è¯¯æ¶ˆæ¯ç‡",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(kafka_server_broker_topic_metrics_failed_produce_requests_per_sec[5m]))",
            "legendFormat": "ç”Ÿäº§å¤±è´¥ç‡"
          },
          {
            "expr": "sum(rate(kafka_server_broker_topic_metrics_failed_fetch_requests_per_sec[5m]))",
            "legendFormat": "æ¶ˆè´¹å¤±è´¥ç‡"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "reqps",
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "green", "value": 0},
                {"color": "yellow", "value": 1},
                {"color": "red", "value": 10}
              ]
            }
          }
        }
      }
    ]
  }
}
```

---

## ğŸš¨ å‘Šè­¦è§„åˆ™

### 1. é›†ç¾¤å¥åº·å‘Šè­¦

```yaml
# kafka_alerts.yml
groups:
  - name: kafka.cluster.health
    rules:
      - alert: KafkaBrokerDown
        expr: kafka_server_broker_state == 0
        for: 1m
        labels:
          severity: critical
          service: kafka
        annotations:
          summary: "Kafka Broker ç¦»çº¿"
          description: "Broker {{ $labels.broker_id }} å·²ç¦»çº¿è¶…è¿‡ 1 åˆ†é’Ÿ"

      - alert: KafkaControllerDown
        expr: kafka_controller_active_controller_count == 0
        for: 30s
        labels:
          severity: critical
          service: kafka
        annotations:
          summary: "Kafka æ§åˆ¶å™¨ä¸å¯ç”¨"
          description: "é›†ç¾¤ä¸­æ²¡æœ‰æ´»è·ƒçš„æ§åˆ¶å™¨"

      - alert: KafkaOfflinePartitions
        expr: kafka_controller_offline_partitions_count > 0
        for: 1m
        labels:
          severity: critical
          service: kafka
        annotations:
          summary: "Kafka åˆ†åŒºç¦»çº¿"
          description: "æœ‰ {{ $value }} ä¸ªåˆ†åŒºå¤„äºç¦»çº¿çŠ¶æ€"

      - alert: KafkaUnderReplicatedPartitions
        expr: sum(kafka_server_replica_manager_under_replicated_partitions) > 0
        for: 5m
        labels:
          severity: warning
          service: kafka
        annotations:
          summary: "Kafka åˆ†åŒºå‰¯æœ¬ä¸è¶³"
          description: "æœ‰ {{ $value }} ä¸ªåˆ†åŒºçš„å‰¯æœ¬æ•°ä¸è¶³"
```

### 2. æ€§èƒ½å‘Šè­¦

```yaml
  - name: kafka.performance
    rules:
      - alert: KafkaHighProducerLatency
        expr: histogram_quantile(0.99, rate(kafka_network_request_metrics_total_time_ms_bucket{request="Produce"}[5m])) > 1000
        for: 5m
        labels:
          severity: warning
          service: kafka
        annotations:
          summary: "Kafka ç”Ÿäº§è€…å»¶è¿Ÿè¿‡é«˜"
          description: "99th ç™¾åˆ†ä½ç”Ÿäº§è€…å»¶è¿Ÿä¸º {{ $value }}msï¼Œè¶…è¿‡é˜ˆå€¼"

      - alert: KafkaHighConsumerLag
        expr: kafka_consumer_lag_sum > 10000
        for: 5m
        labels:
          severity: warning
          service: kafka
        annotations:
          summary: "Kafka æ¶ˆè´¹è€…å»¶è¿Ÿè¿‡é«˜"
          description: "æ¶ˆè´¹è€…ç»„ {{ $labels.group }} åœ¨ä¸»é¢˜ {{ $labels.topic }} ä¸Šçš„å»¶è¿Ÿä¸º {{ $value }} æ¡æ¶ˆæ¯"

      - alert: KafkaLowThroughput
        expr: sum(rate(kafka_server_broker_topic_metrics_messages_in_per_sec[5m])) < 100
        for: 10m
        labels:
          severity: info
          service: kafka
        annotations:
          summary: "Kafka ååé‡è¾ƒä½"
          description: "é›†ç¾¤æ¶ˆæ¯ååé‡ä¸º {{ $value }} æ¶ˆæ¯/ç§’ï¼Œä½äºé¢„æœŸ"
```

### 3. èµ„æºå‘Šè­¦

```yaml
  - name: kafka.resources
    rules:
      - alert: KafkaHighMemoryUsage
        expr: (jvm_memory_heap_used / jvm_memory_heap_max) * 100 > 85
        for: 5m
        labels:
          severity: warning
          service: kafka
        annotations:
          summary: "Kafka JVM å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "Broker {{ $labels.instance }} JVM å †å†…å­˜ä½¿ç”¨ç‡ä¸º {{ $value }}%"

      - alert: KafkaHighDiskUsage
        expr: (1 - node_filesystem_avail_bytes{mountpoint="/kafka-logs"} / node_filesystem_size_bytes{mountpoint="/kafka-logs"}) * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: kafka
        annotations:
          summary: "Kafka ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "èŠ‚ç‚¹ {{ $labels.instance }} ç£ç›˜ä½¿ç”¨ç‡ä¸º {{ $value }}%"

      - alert: KafkaHighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 10m
        labels:
          severity: warning
          service: kafka
        annotations:
          summary: "Kafka èŠ‚ç‚¹ CPU ä½¿ç”¨ç‡è¿‡é«˜"
          description: "èŠ‚ç‚¹ {{ $labels.instance }} CPU ä½¿ç”¨ç‡ä¸º {{ $value }}%"
```

---

## ğŸ“ æ—¥å¿—ç›‘æ§

### 1. æ—¥å¿—æ”¶é›†é…ç½®

#### Filebeat é…ç½®

```yaml
# filebeat.yml
filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - /var/log/kafka/server.log
      - /var/log/kafka/controller.log
      - /var/log/kafka/kafka-request.log
    fields:
      service: kafka
      environment: production
    fields_under_root: true
    multiline.pattern: '^\d{4}-\d{2}-\d{2}'
    multiline.negate: true
    multiline.match: after

  - type: log
    enabled: true
    paths:
      - /var/log/redpanda/redpanda.log
    fields:
      service: redpanda
      environment: production
    fields_under_root: true

output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  index: "kafka-logs-%{+yyyy.MM.dd}"

processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
  - add_docker_metadata: ~
  - add_kubernetes_metadata: ~

logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
```

#### Logstash é…ç½®

```ruby
# logstash.conf
input {
  beats {
    port => 5044
  }
}

filter {
  if [service] == "kafka" {
    grok {
      match => { 
        "message" => "\[%{TIMESTAMP_ISO8601:timestamp}\] %{LOGLEVEL:level} %{GREEDYDATA:message_content} \(%{DATA:logger}\)"
      }
    }
    
    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss,SSS" ]
    }
    
    if [level] == "ERROR" {
      mutate {
        add_tag => [ "error" ]
      }
    }
    
    if [level] == "WARN" {
      mutate {
        add_tag => [ "warning" ]
      }
    }
  }
  
  if [service] == "redpanda" {
    json {
      source => "message"
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{service}-logs-%{+YYYY.MM.dd}"
  }
  
  if "error" in [tags] {
    slack {
      url => "${SLACK_WEBHOOK_URL}"
      channel => "#kafka-alerts"
      username => "Kafka Monitor"
      icon_emoji => ":warning:"
      format => "Kafka Error: %{message_content}"
    }
  }
}
```

### 2. æ—¥å¿—åˆ†ææŸ¥è¯¢

#### Elasticsearch æŸ¥è¯¢ç¤ºä¾‹

```json
{
  "query": {
    "bool": {
      "must": [
        {
          "range": {
            "@timestamp": {
              "gte": "now-1h"
            }
          }
        },
        {
          "term": {
            "service": "kafka"
          }
        },
        {
          "term": {
            "level": "ERROR"
          }
        }
      ]
    }
  },
  "aggs": {
    "error_types": {
      "terms": {
        "field": "logger.keyword",
        "size": 10
      }
    },
    "error_timeline": {
      "date_histogram": {
        "field": "@timestamp",
        "interval": "5m"
      }
    }
  }
}
```

#### Kibana ä»ªè¡¨æ¿é…ç½®

```json
{
  "version": "7.15.0",
  "objects": [
    {
      "id": "kafka-error-dashboard",
      "type": "dashboard",
      "attributes": {
        "title": "Kafka é”™è¯¯ç›‘æ§",
        "panelsJSON": "[{\"version\":\"7.15.0\",\"panelIndex\":\"1\",\"gridData\":{\"x\":0,\"y\":0,\"w\":24,\"h\":15},\"panelRefName\":\"panel_1\",\"embeddableConfig\":{},\"id\":\"kafka-error-timeline\",\"type\":\"visualization\"},{\"version\":\"7.15.0\",\"panelIndex\":\"2\",\"gridData\":{\"x\":24,\"y\":0,\"w\":24,\"h\":15},\"panelRefName\":\"panel_2\",\"embeddableConfig\":{},\"id\":\"kafka-error-types\",\"type\":\"visualization\"}]"
      }
    }
  ]
}
```

---

## âš¡ æ€§èƒ½è°ƒä¼˜

### 1. ç›‘æ§é©±åŠ¨çš„è°ƒä¼˜

#### åŸºäºæŒ‡æ ‡çš„è°ƒä¼˜å»ºè®®

```typescript
@Injectable()
export class KafkaPerformanceTuner {
  constructor(
    private prometheusService: PrometheusService,
    private configService: ConfigService,
  ) {}

  async analyzePerformance(): Promise<TuningRecommendations> {
    const metrics = await this.collectMetrics();
    const recommendations: TuningRecommendations = {
      broker: [],
      producer: [],
      consumer: [],
      cluster: [],
    };

    // åˆ†æç”Ÿäº§è€…æ€§èƒ½
    if (metrics.producerLatencyP99 > 1000) {
      recommendations.producer.push({
        parameter: 'batch.size',
        currentValue: await this.getConfigValue('batch.size'),
        recommendedValue: '32768',
        reason: 'é«˜å»¶è¿Ÿï¼Œå»ºè®®å¢åŠ æ‰¹æ¬¡å¤§å°ä»¥æé«˜ååé‡',
      });
    }

    // åˆ†ææ¶ˆè´¹è€…å»¶è¿Ÿ
    if (metrics.maxConsumerLag > 10000) {
      recommendations.consumer.push({
        parameter: 'fetch.min.bytes',
        currentValue: await this.getConfigValue('fetch.min.bytes'),
        recommendedValue: '1048576',
        reason: 'æ¶ˆè´¹å»¶è¿Ÿè¿‡é«˜ï¼Œå»ºè®®å¢åŠ æ‹‰å–æ‰¹æ¬¡å¤§å°',
      });
    }

    // åˆ†æç£ç›˜ä½¿ç”¨
    if (metrics.diskUsagePercent > 80) {
      recommendations.broker.push({
        parameter: 'log.retention.hours',
        currentValue: await this.getConfigValue('log.retention.hours'),
        recommendedValue: '168',
        reason: 'ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®å‡å°‘æ—¥å¿—ä¿ç•™æ—¶é—´',
      });
    }

    return recommendations;
  }

  private async collectMetrics(): Promise<PerformanceMetrics> {
    const queries = {
      producerLatencyP99: 'histogram_quantile(0.99, rate(kafka_network_request_metrics_total_time_ms_bucket{request="Produce"}[5m]))',
      maxConsumerLag: 'max(kafka_consumer_lag_sum)',
      diskUsagePercent: 'max((1 - node_filesystem_avail_bytes{mountpoint="/kafka-logs"} / node_filesystem_size_bytes{mountpoint="/kafka-logs"}) * 100)',
      memoryUsagePercent: 'max((jvm_memory_heap_used / jvm_memory_heap_max) * 100)',
      throughputMsgPerSec: 'sum(rate(kafka_server_broker_topic_metrics_messages_in_per_sec[5m]))',
    };

    const results: PerformanceMetrics = {};
    
    for (const [key, query] of Object.entries(queries)) {
      const result = await this.prometheusService.query(query);
      results[key] = parseFloat(result.data.result[0]?.value[1] || '0');
    }

    return results;
  }
}

interface TuningRecommendations {
  broker: TuningRecommendation[];
  producer: TuningRecommendation[];
  consumer: TuningRecommendation[];
  cluster: TuningRecommendation[];
}

interface TuningRecommendation {
  parameter: string;
  currentValue: string;
  recommendedValue: string;
  reason: string;
}

interface PerformanceMetrics {
  [key: string]: number;
}
```

### 2. è‡ªåŠ¨åŒ–è°ƒä¼˜

```typescript
@Injectable()
export class AutoTuningService {
  private readonly TUNING_RULES = [
    {
      condition: (metrics: PerformanceMetrics) => metrics.producerLatencyP99 > 1000,
      action: async () => {
        await this.updateBrokerConfig('num.network.threads', '8');
        await this.updateBrokerConfig('num.io.threads', '16');
      },
      description: 'å¢åŠ ç½‘ç»œå’Œ I/O çº¿ç¨‹æ•°ä»¥é™ä½å»¶è¿Ÿ',
    },
    {
      condition: (metrics: PerformanceMetrics) => metrics.memoryUsagePercent > 85,
      action: async () => {
        await this.updateBrokerConfig('log.segment.bytes', '536870912'); // 512MB
        await this.triggerLogCompaction();
      },
      description: 'å‡å°‘æ—¥å¿—æ®µå¤§å°å¹¶è§¦å‘å‹ç¼©ä»¥é‡Šæ”¾å†…å­˜',
    },
  ];

  @Cron('0 */6 * * *') // æ¯6å°æ—¶æ‰§è¡Œä¸€æ¬¡
  async performAutoTuning(): Promise<void> {
    const metrics = await this.collectCurrentMetrics();
    const appliedTunings: string[] = [];

    for (const rule of this.TUNING_RULES) {
      if (rule.condition(metrics)) {
        try {
          await rule.action();
          appliedTunings.push(rule.description);
          
          // ç­‰å¾…é…ç½®ç”Ÿæ•ˆ
          await this.sleep(30000);
        } catch (error) {
          console.error(`è‡ªåŠ¨è°ƒä¼˜å¤±è´¥: ${rule.description}`, error);
        }
      }
    }

    if (appliedTunings.length > 0) {
      await this.notifyTuningActions(appliedTunings);
    }
  }

  private async updateBrokerConfig(key: string, value: string): Promise<void> {
    // ä½¿ç”¨ Kafka Admin API æ›´æ–°é…ç½®
    const admin = this.kafkaService.admin();
    await admin.alterConfigs({
      validateOnly: false,
      resources: [{
        type: 2, // BROKER
        name: '0',
        configEntries: [{
          name: key,
          value: value,
        }],
      }],
    });
  }
}
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### 1. å¸¸è§é—®é¢˜è¯Šæ–­

#### æ¶ˆè´¹è€…å»¶è¿Ÿé—®é¢˜

```bash
#!/bin/bash
# æ¶ˆè´¹è€…å»¶è¿Ÿè¯Šæ–­è„šæœ¬

echo "=== æ¶ˆè´¹è€…å»¶è¿Ÿè¯Šæ–­ ==="

# 1. æ£€æŸ¥æ¶ˆè´¹è€…ç»„çŠ¶æ€
kafka-consumer-groups.sh --bootstrap-server localhost:9092 \
  --describe --group user-service-group

# 2. æ£€æŸ¥ä¸»é¢˜åˆ†åŒºåˆ†å¸ƒ
kafka-topics.sh --bootstrap-server localhost:9092 \
  --describe --topic user-events

# 3. æ£€æŸ¥ç”Ÿäº§è€…æ€§èƒ½
kafka-producer-perf-test.sh --topic user-events \
  --num-records 10000 --record-size 1024 \
  --throughput 1000 --producer-props bootstrap.servers=localhost:9092

# 4. æ£€æŸ¥æ¶ˆè´¹è€…æ€§èƒ½
kafka-consumer-perf-test.sh --topic user-events \
  --messages 10000 --bootstrap-server localhost:9092

# 5. åˆ†ææ—¥å¿—ä¸­çš„é”™è¯¯
grep -i "error\|exception\|timeout" /var/log/kafka/server.log | tail -20
```

#### åˆ†åŒºä¸å¹³è¡¡é—®é¢˜

```bash
#!/bin/bash
# åˆ†åŒºé‡å¹³è¡¡è„šæœ¬

echo "=== åˆ†åŒºé‡å¹³è¡¡è¯Šæ–­ ==="

# 1. ç”Ÿæˆé‡å¹³è¡¡è®¡åˆ’
kafka-reassign-partitions.sh --bootstrap-server localhost:9092 \
  --topics-to-move-json-file topics.json \
  --broker-list "0,1,2" --generate

# 2. æ‰§è¡Œé‡å¹³è¡¡
kafka-reassign-partitions.sh --bootstrap-server localhost:9092 \
  --reassignment-json-file reassignment.json --execute

# 3. éªŒè¯é‡å¹³è¡¡çŠ¶æ€
kafka-reassign-partitions.sh --bootstrap-server localhost:9092 \
  --reassignment-json-file reassignment.json --verify

# 4. æ£€æŸ¥é¦–é€‰å‰¯æœ¬é€‰ä¸¾
kafka-leader-election.sh --bootstrap-server localhost:9092 \
  --election-type preferred --all-topic-partitions
```

### 2. è‡ªåŠ¨åŒ–æ•…éšœæ¢å¤

```typescript
@Injectable()
export class KafkaHealthChecker {
  constructor(
    private kafkaService: KafkaService,
    private alertService: AlertService,
  ) {}

  @Cron('*/5 * * * *') // æ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
  async performHealthCheck(): Promise<void> {
    const healthStatus = await this.checkClusterHealth();
    
    if (!healthStatus.healthy) {
      await this.attemptAutoRecovery(healthStatus.issues);
    }
  }

  private async checkClusterHealth(): Promise<HealthStatus> {
    const issues: HealthIssue[] = [];
    
    try {
      // æ£€æŸ¥ Broker è¿æ¥
      const admin = this.kafkaService.admin();
      const metadata = await admin.fetchTopicMetadata();
      
      // æ£€æŸ¥ç¦»çº¿åˆ†åŒº
      const offlinePartitions = metadata.topics
        .flatMap(topic => topic.partitions)
        .filter(partition => partition.leader === -1);
      
      if (offlinePartitions.length > 0) {
        issues.push({
          type: 'offline_partitions',
          severity: 'critical',
          count: offlinePartitions.length,
          details: offlinePartitions,
        });
      }

      // æ£€æŸ¥æœªåŒæ­¥å‰¯æœ¬
      const underReplicatedPartitions = metadata.topics
        .flatMap(topic => topic.partitions)
        .filter(partition => partition.isr.length < partition.replicas.length);
      
      if (underReplicatedPartitions.length > 0) {
        issues.push({
          type: 'under_replicated_partitions',
          severity: 'warning',
          count: underReplicatedPartitions.length,
          details: underReplicatedPartitions,
        });
      }

    } catch (error) {
      issues.push({
        type: 'connection_error',
        severity: 'critical',
        error: error.message,
      });
    }

    return {
      healthy: issues.length === 0,
      issues,
      timestamp: new Date(),
    };
  }

  private async attemptAutoRecovery(issues: HealthIssue[]): Promise<void> {
    for (const issue of issues) {
      switch (issue.type) {
        case 'offline_partitions':
          await this.recoverOfflinePartitions();
          break;
        case 'under_replicated_partitions':
          await this.triggerPreferredReplicaElection();
          break;
        case 'connection_error':
          await this.restartKafkaService();
          break;
      }
    }
  }

  private async recoverOfflinePartitions(): Promise<void> {
    // è§¦å‘åˆ†åŒºæ¢å¤é€»è¾‘
    console.log('å°è¯•æ¢å¤ç¦»çº¿åˆ†åŒº...');
    // å®ç°åˆ†åŒºæ¢å¤é€»è¾‘
  }

  private async triggerPreferredReplicaElection(): Promise<void> {
    // è§¦å‘é¦–é€‰å‰¯æœ¬é€‰ä¸¾
    console.log('è§¦å‘é¦–é€‰å‰¯æœ¬é€‰ä¸¾...');
    // å®ç°å‰¯æœ¬é€‰ä¸¾é€»è¾‘
  }

  private async restartKafkaService(): Promise<void> {
    // é‡å¯ Kafka æœåŠ¡ï¼ˆè°¨æ…æ“ä½œï¼‰
    console.log('å°è¯•é‡å¯ Kafka æœåŠ¡...');
    await this.alertService.sendCriticalAlert('Kafka æœåŠ¡é‡å¯');
  }
}

interface HealthStatus {
  healthy: boolean;
  issues: HealthIssue[];
  timestamp: Date;
}

interface HealthIssue {
  type: string;
  severity: 'info' | 'warning' | 'critical';
  count?: number;
  details?: any;
  error?: string;
}
```

---

## ğŸ“š æœ€ä½³å®è·µ

### 1. ç›‘æ§ç­–ç•¥

- **åˆ†å±‚ç›‘æ§**ï¼šåŸºç¡€è®¾æ–½ â†’ åº”ç”¨ â†’ ä¸šåŠ¡æŒ‡æ ‡
- **ä¸»åŠ¨ç›‘æ§**ï¼šé¢„æµ‹æ€§å‘Šè­¦ï¼Œè€Œéè¢«åŠ¨å“åº”
- **ç«¯åˆ°ç«¯ç›‘æ§**ï¼šä»ç”Ÿäº§è€…åˆ°æ¶ˆè´¹è€…çš„å®Œæ•´é“¾è·¯
- **ä¸šåŠ¡å…³è”**ï¼šå°†æŠ€æœ¯æŒ‡æ ‡ä¸ä¸šåŠ¡å½±å“å…³è”

### 2. å‘Šè­¦è®¾è®¡

- **åˆ†çº§å‘Šè­¦**ï¼šCritical â†’ Warning â†’ Info
- **æ™ºèƒ½é™å™ª**ï¼šé¿å…å‘Šè­¦é£æš´
- **ä¸Šä¸‹æ–‡ä¿¡æ¯**ï¼šæä¾›è¶³å¤Ÿçš„æ•…éšœæ’é™¤ä¿¡æ¯
- **è‡ªåŠ¨æ¢å¤**ï¼šèƒ½è‡ªåŠ¨æ¢å¤çš„é—®é¢˜ä¸åº”è¯¥å‘Šè­¦

### 3. æ€§èƒ½ä¼˜åŒ–

- **åŸºå‡†æµ‹è¯•**ï¼šå»ºç«‹æ€§èƒ½åŸºçº¿
- **æŒç»­ç›‘æ§**ï¼šç›‘æ§æ€§èƒ½è¶‹åŠ¿å˜åŒ–
- **å®¹é‡è§„åˆ’**ï¼šåŸºäºç›‘æ§æ•°æ®è¿›è¡Œå®¹é‡è§„åˆ’
- **è‡ªåŠ¨è°ƒä¼˜**ï¼šåŸºäºæŒ‡æ ‡è‡ªåŠ¨è°ƒæ•´é…ç½®

---

## ğŸ”— ç›¸å…³é“¾æ¥

- [Kafka ç›‘æ§æŒ‡å—](https://kafka.apache.org/documentation/#monitoring)
- [Redpanda ç›‘æ§æ–‡æ¡£](https://docs.redpanda.com/docs/manage/monitoring/)
- [Prometheus Kafka Exporter](https://github.com/danielqsj/kafka_exporter)
- [Grafana Kafka ä»ªè¡¨æ¿](https://grafana.com/grafana/dashboards/721)

---

**æœ€åæ›´æ–°**ï¼š2025-01-26  
**é…ç½®ç‰ˆæœ¬**ï¼šv1.0.0  
**ç»´æŠ¤å›¢é˜Ÿ**ï¼šDevOps å›¢é˜Ÿ